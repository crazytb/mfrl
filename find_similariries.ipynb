{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "def weight_similarity(model1, model2):\n",
    "    \"\"\"Calculate cosine similarity between flattened model weights.\"\"\"\n",
    "    weights1 = torch.cat([p.view(-1) for p in model1.parameters()])\n",
    "    weights2 = torch.cat([p.view(-1) for p in model2.parameters()])\n",
    "    return F.cosine_similarity(weights1.unsqueeze(0), weights2.unsqueeze(0)).item()\n",
    "\n",
    "def output_similarity(model1, model2, input_data):\n",
    "    \"\"\"Calculate Pearson correlation between model outputs.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        out1 = model1(input_data).numpy().flatten()\n",
    "        out2 = model2(input_data).numpy().flatten()\n",
    "    return pearsonr(out1, out2)[0]\n",
    "\n",
    "def activation_similarity(model1, model2, input_data):\n",
    "    \"\"\"Compare activations of each layer.\"\"\"\n",
    "    similarities = []\n",
    "    \n",
    "    def hook_fn(module, input, output):\n",
    "        return output\n",
    "    \n",
    "    for (name1, module1), (name2, module2) in zip(model1.named_modules(), model2.named_modules()):\n",
    "        if isinstance(module1, nn.Linear) and isinstance(module2, nn.Linear):\n",
    "            handle1 = module1.register_forward_hook(hook_fn)\n",
    "            handle2 = module2.register_forward_hook(hook_fn)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                out1 = model1(input_data)\n",
    "                out2 = model2(input_data)\n",
    "            \n",
    "            act1 = module1.output.numpy().flatten()\n",
    "            act2 = module2.output.numpy().flatten()\n",
    "            \n",
    "            similarity = pearsonr(act1, act2)[0]\n",
    "            similarities.append((name1, similarity))\n",
    "            \n",
    "            handle1.remove()\n",
    "            handle2.remove()\n",
    "    \n",
    "    return similarities\n",
    "\n",
    "def compare_models(model1, model2, input_data):\n",
    "    \"\"\"Compare two models using multiple similarity metrics.\"\"\"\n",
    "    weight_sim = weight_similarity(model1, model2)\n",
    "    output_sim = output_similarity(model1, model2, input_data)\n",
    "    activation_sims = activation_similarity(model1, model2, input_data)\n",
    "    \n",
    "    print(f\"Weight Similarity: {weight_sim:.4f}\")\n",
    "    print(f\"Output Similarity: {output_sim:.4f}\")\n",
    "    print(\"Activation Similarities:\")\n",
    "    for name, sim in activation_sims:\n",
    "        print(f\"  {name}: {sim:.4f}\")\n",
    "\n",
    "# Example usage\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.Linear(10, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Create two models\n",
    "model1 = SimpleNet()\n",
    "model2 = SimpleNet()\n",
    "\n",
    "# Generate some random input data\n",
    "input_data = torch.randn(100, 10)\n",
    "\n",
    "# Compare the models\n",
    "# compare_models(model1, model2, input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import main_mfrl_REINFORCE_RA2C as RA2C\n",
    "from mfrl_lib.lib import *\n",
    "import torch\n",
    "\n",
    "agents = [RA2C.Agent(topology, i) for i in range(node_n)]\n",
    "for i in range(node_n):\n",
    "    agents[i].pinet.load_state_dict(torch.load(f\"models/RA2C_agent_{i}.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0160, 0.0866]]], device='cuda:0', grad_fn=<ViewBackward0>),\n",
       " tensor([[[0.4286]]], device='cuda:0', grad_fn=<ViewBackward0>),\n",
       " tensor([[[-0.1347,  0.1667,  0.0982,  0.0410,  0.1112, -0.1272, -0.1506,\n",
       "           -0.0202, -0.0423, -0.1044,  0.0402,  0.0169,  0.0850, -0.0426,\n",
       "            0.0573, -0.0425, -0.0681,  0.0520, -0.0306,  0.1004,  0.0918,\n",
       "            0.1633,  0.0376, -0.0949, -0.0646, -0.1189,  0.0903, -0.0103,\n",
       "           -0.0680,  0.1779,  0.0561,  0.0513]]], device='cuda:0',\n",
       "        grad_fn=<CudnnRnnBackward0>),\n",
       " tensor([[[-0.2378,  0.2745,  0.1753,  0.0765,  0.1931, -0.2018, -0.2510,\n",
       "           -0.0386, -0.0791, -0.1923,  0.0746,  0.0291,  0.1457, -0.0921,\n",
       "            0.1103, -0.0966, -0.1212,  0.0981, -0.0668,  0.1725,  0.2007,\n",
       "            0.2732,  0.0708, -0.1552, -0.1359, -0.2274,  0.1484, -0.0207,\n",
       "           -0.1142,  0.2966,  0.1233,  0.0876]]], device='cuda:0',\n",
       "        grad_fn=<CudnnRnnBackward0>))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agents[0].pinet((torch.Tensor([[[0.5, 0.5, 0.0]]])).to(device),\n",
    "                torch.zeros(1, 1, 32).to(device),\n",
    "                torch.zeros(1, 1, 32).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Pinet.forward() missing 2 required positional arguments: 'h' and 'c'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moutput_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43magents\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpinet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magents\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpinet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m, in \u001b[0;36moutput_similarity\u001b[0;34m(model1, model2, input_data)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calculate Pearson correlation between model outputs.\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 16\u001b[0m     out1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel1\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     17\u001b[0m     out2 \u001b[38;5;241m=\u001b[39m model2(input_data)\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pearsonr(out1, out2)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/torch-cert/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch-cert/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Pinet.forward() missing 2 required positional arguments: 'h' and 'c'"
     ]
    }
   ],
   "source": [
    "output_similarity(agents[0].pinet, agents[7].pinet, ((torch.Tensor([[[0.5, 0.5, 0.0]]])).to(device),\n",
    "                                                     torch.zeros(1, 1, 32).to(device),\n",
    "                                                     torch.zeros(1, 1, 32).to(device)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-cert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
